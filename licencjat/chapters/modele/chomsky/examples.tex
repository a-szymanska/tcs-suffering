\subsubsection{Przykład języka regularnego}

\begin{theorem}
Język \( \set{a^n : n \in \natural} \) jest regularny. 
\end{theorem}
\begin{proof}
Tworzymy wyrażenie regularne postaci \(a^*\), a jak wiadomo, wyrażenia regularne można zamieniać na DFA.
\end{proof}

\subsubsection{Przykład języka bezkontekstowego}
\label{cfl_example}

\begin{theorem}
Język  \( \set{a^nb^n : n \in \natural} \) jest bezkontekstowy.
\end{theorem}
\begin{proof}
    Tworzymy gramatykę bezkontekstową z następującymi produkcjami: \begin{enumerate}
        \item \(S \rightarrow aSb \)
        \item \(S \rightarrow \eps \)
    \end{enumerate}
    gdzie \(S\) to symbol startowy.
\end{proof}

Ponadto, korzystając z lematu o pompowaniu dla języków regularnych (sekcja \ref{regular-pumping}) możemy pokazać następujące twierdzenie:
\begin{theorem}
    Język
    \[
        L = \set{a^nb^n : n \in \natural}
    \]
    nie jest językiem regularnym.
\end{theorem}

\begin{proof}
    Chcemy pokazać, że \(L\) nie spełnia lematu o pompowaniu, czyli że: 
    \[
        \forall_{n>0}\; \exists_{w \in L}\; \forall_{xyz=w :\: \abs{xy} \leq n \land \abs{y} \geq 1}\; \exists_{i \in N}\; xy^iz \not \in L 
    \] 
    Można o tym myśleć jako o grze: Przeciwnik podaje nam stałą \(n\), a my odpowiadmy słowem \( w \). On dzieli je nam na 3 części, które spełniają warunki lematu. Możemy ,,napompować'' część \(y\). Wygrywamy, jeśli słowo nie należy do \(L\). Jeśli mamy strategię wygrywającą, to znaczy że język nie jest regularny. 
    
    W przypadku języka \( L \) jako \( w \) można podać słowo postaci \(a^{2n}b^{2n}\), które niewątpliwie należy do \(L\).
    Niezależnie od podziału \( w = xyz\), który spełnia warunki: \(\abs{xy} \leq n \) i \(\abs{y} \geq 1\), dla jakiegoś \(k\) mamy \(xy = a^k\). Wobec tego \(y = a^l\) dla \( 0 < l < n \). W takim razie, ustalając \(i = 0\), otrzymując słowo postaci \(a^{2n-l}b^{2n}\), które nie należy do języka \( L \). 
\end{proof}

\subsubsection{Przykład języka kontekstowego}
\label{csl_example}
\begin{theorem}
    Język \( \set{a^nb^nc^n : n \in \natural} \) jest kontekstowy.
\end{theorem}
\begin{proof}
    Dowód będziemy realizować poprzez gramatykę kontekstową, ale można też pokazać LBA, które rozpoznaje ten język. Można skonstruować LBA, które w każdym przejściu usuwa z taśmy literę \(a\), potem literę \(b\) i \(c\) i pilnuje ich odpowiedniej kolejności stanami. 

    W przypadku gramatyki kontekstowej warto zauważyć, że w CSG dozwolone są przejścia typu \(AB \rightarrow BA\), gdzie \(A, B\) są nieterminalami, ponieważ możemy wprowadzić dodatkowe nieterminale (nazwijmy je \(Z_1\), \(Z_2\)) oraz następujące produkcje:
    \begin{enumerate}
        \item \(AB \rightarrow Z_1B\)
        \item \(Z_1B \rightarrow Z_1Z_2 \) 
        \item \( Z_1Z_2 \rightarrow AZ_2 \)
        \item \( AZ_2 \rightarrow BA \)        
    \end{enumerate}
    Dla każdej pary nieterminali \(A, B\) którą chcemy zamienić miejscami konieczna jest oddzielna para \(Z_1, Z_2\) do implementacji takiego przejścia. 

    Tworzymy CSG o następujących produkcjach (nieterminale to \(S, A, B, C, D, E\); symbol startowy to \(S\)):    
    \begin{enumerate}
        \item \( S \rightarrow DABCE \)
        \item \( E \rightarrow ABCE \mid \eps \) 
        \item \( DA \rightarrow Da, Da \rightarrow a\) 
        \item \( aA \rightarrow aa \)
        \item \( aB  \rightarrow ab \), \( bB \rightarrow bb \)
        \item \( bC \rightarrow bc \)
        \item \( cC \rightarrow cc \)
        \item \( BA \rightarrow AB \), \( CB \rightarrow BC \) , \(CA \rightarrow AC\)
    \end{enumerate}

    Semantykę symboli jest następująca:
    \begin{itemize}
        \item \(S\) to symbol startowy;
        \item \(D\) to \textit{delimiter} -- nieterminal, który (o ile znajduje się w którymś momencie wywodu) zawsze stoi na lewym końcu formy zdaniowej;
        \item \(E\) to symbol służący do kopiowania nieterminali \(A, B, C\);
        \item \(A, B, C\) to nieterminale, które w określonych warunkach mogą zmienić się w terminale \(a, b, c\). 
    \end{itemize}
    
    Na początek tworzymy \(A, B, C\), a dzięki przejściom, które mogą je permutować, sortujemy je tak, by wygenerowały słowo postaci \(a^nb^nc^n\). 
    
    Dowodzić tego, że gramatyka \(G\) generuje język \(L = \set{a^nb^nc^n : n \in \natural}\) można przez pokazanie inkluzji w obie strony.
    
    
    \begin{lemma}
        \(L \subseteq L(G)\)
    \end{lemma}
    \begin{proof}
        Pokażemy, że dla dowolnego słowa \(w\) zachodzi:
        \[ w \in L \implies w \in L(G) \] 
        
        Wiemy, że \(w = a^nb^nc^n\) dla jakiegoś \(n \in \natural\). Pokażemy wywód w \(G\), który generuje \(w\) w sposób następujący:
        \[ 
            S \rightarrow_G DABCE \rightarrow_G DABCABCE \rightarrow^*_G D \overbrace{ABC \dots ABC}^{\text{\(n\) razy}}E
        \]
        \[
            D \overbrace{ABC \dots ABC}^{\text{\(n\) razy}}E \rightarrow_G D \overbrace{ABC \dots ABC}^{\text{\(n\) razy}}
        \]
        Przesuwamy wszystkie nieterminale \(C\) na sam koniec, korzystając z produkcji \(CA \rightarrow AC\) i \(CB \rightarrow BC\).
        
        Następnie ustawiamy wszystkie nieterminale \(B\) tak, żeby znajdywały się po terminalach \(A\), korzystając z produkcji \(BA \rightarrow AB\). 
        
        Każde takie przejście usuwa inwersję, a jeśli gdzieś jest inwersja to znaczy że gdzieś mamy nieterminale obok siebie, które mogą być zamienione tym przejściem. Zrobiliśmy tak zwane sortowanie bąbelkowe. 
        Otrzymujemy tą metodą coś postaci: 
        \[
            D \overbrace{A \dots A}^{\text{\(n\) razy}} \overbrace{B \dots B}^{\text{\(n\) razy}}
            \overbrace{C \dots C}^{\text{\(n\) razy}}
        \]
        Teraz elegancko korzystamy z produkcji \( DA \rightarrow Da \) oraz \(Da \rightarrow a\):
        \[
        D \overbrace{A \dots A}^{\text{\(n\) razy}} \overbrace{B \dots B}^{\text{\(n\) razy}}
        \overbrace{C \dots C}^{\text{\(n\) razy}} \rightarrow_G Da\overbrace{A \dots A}^{\text{\(n-1\) razy}} \overbrace{B \dots B}^{\text{\(n\) razy}}
        \overbrace{C \dots C}^{\text{\(n\) razy}}
        \rightarrow_G a\overbrace{A \dots A}^{\text{\(n-1\) razy}} \overbrace{B \dots B}^{\text{\(n\) razy}}
        \overbrace{C \dots C}^{\text{\(n\) razy}}
        \]
        Następnie, korzystając z produkcji \(aA \rightarrow aa\), dostajemy:
        \[ 
            \overbrace{a \dots a}^{\text{\(n\) razy}} \overbrace{B \dots B}^{\text{\(n\) razy}}
            \overbrace{C \dots C}^{\text{\(n\) razy}}
        \]
        Wreszcie, wykorzystując produkcję \(aB \rightarrow ab \), \(bB \rightarrow bb\), \(bC \rightarrow bc\), \( cC \rightarrow cc\), udaje się otrzymać:
        \[ 
            \overbrace{a \dots a}^{\text{\(n\) razy}} \overbrace{B \dots B}^{\text{\(n\) razy}}
            \overbrace{C \dots C}^{\text{\(n\) razy}}
            \rightarrow_G^{*}
            \overbrace{a \dots a}^{\text{\(n\) razy}} \overbrace{b \dots b}^{\text{\(n\) razy}}
            \overbrace{c \dots c}^{\text{\(n\) razy}}
            = w
        \]
    \end{proof}
    
    \begin{lemma}
        \(L(G) \subseteq L\)
    \end{lemma}
    \begin{proof}
        Pokażemy, że dla dowolnego słowa \(w\) zachodzi:
        \[ w \in L(G) \implies w \in L \] 
        
        Wszystkie słowa generowane przez \(G\) mają tyle samo wystąpień terminali \(a\), \(b\) i \(c\), jako że każda produkcja, która dodaje terminal \(a\), usuwa jeden nieterminal \(A\) (analogicznie dla \(B\) i \(C\); terminale \(D\), \(E\) i \(S\) nie ,,przechodzą'' w żadną literę). 
        
        Tym samym jedyne, co mogłoby się ,,popsuć'', to kolejność wystąpień liter.
        
        Załóżmy więc nie wprost, że istnieje wywód w \(G\), w wyniku którego otrzymujemy literę \(a\) na pozycji \( \geq n \) (przy indeksowaniu od 0). Słowo, które zostało otrzymane tym wywodem, oznaczmy jako \(w\); \( |w| = 3n\).
        
        Ta litera \( a \) musiała podmienić jakiś nieterminal i z produkcji wynika, że musiał być to nieterminal \(A\). Wystąpiła więc sytuacja:
        \[
            \overbrace{a, b, \text{ lub } c}^{\text{\(k\) razy, \(k \geq n\)}} \; \overbrace{a}^{\text{felerne \(a\)}} \; \overbrace{a, b, \text{ lub } c}^{\text{\(l\) razy, \(l \geq n\)}},
        \]
        gdzie \( l + k = 3n - 1\). Prześledźmy, w jaki sposób doszło do czegoś takiego. Jedyne dwie produkcje, z których można uzyskać terminal \(a\), to \(aA \rightarrow aa\) i \(DA \rightarrow Da\). Jako, że \(D\) jest zawsze skrajnie po lewej stronie wywodu, jedyna produkcja która mogła tutaj dać \(a\) to \(aA \rightarrow aa\).
        
        A zatem, w którymś momencie przeprowadzania wywodu, doszło do przypadku:
        \[
            \alpha a A \beta \rightarrow_G \alpha a \overbrace{a}^{\text{felerne \(a\)}} \beta 
        \]
        
        Ten terminal \(a\), który spowodował konwersję też musiał się skądś wziąć, więc podobnie możemy stracebackować, w jaki sposób on powstał (i znowu otrzymując, że musiał mieć terminal \(a\) po swojej lewej stronie). Innymi słowy: felerne \(a\) musi mieć po swojej lewej w finalnym słowie jedynie inne \(a\). To daje nam sprzeczność, bo wiemy że liter \(a\) jest dokładnie \(n\), a ten terminal znajduje się na miejscu \(\geq n\). 
        
        Czyli wiemy już, że słowa generowane przez \(G\) mają postać:
        \[ 
            \overbrace{a \dots a}^{\text{\(n\) razy}} \beta,
        \]
        gdzie \(\beta \in \set{b, c}^*\). Analogiczny dowód przeprowadzamy dla liter \(b\), pokazując, że \(G\) generuje jedynie słowa postaci \( a^nb^nc^n \).
    \end{proof}
    
    Ponadto język ten nie jest bezkontekstowy -- jest to przykład zastosowania lematu o pompowaniu dla języków bezkontekstowych (sekcja \ref{context-pumping}).
\end{proof}

\subsubsection{Przykład języka rekurencyjnego}
\label{recursive-example}

\textbf{Uwaga.} Jak było już wspomniane -- przynajmniej anglojęzyczna Wikipedia nie notuje języków rekurencyjnych w hierarchi Chomsky'ego. Dla porządku podamy jednak przykład języka rekurencyjnego, który nie jest kontekstowy. 

Żeby zrozumieć co tu się będzie działo, należy zapoznać się z sekcją \ref{lhp}, w której wprowadzone jest pojęcie uniwersalnej maszyny Turinga. 

\begin{theorem}
    Język \( L = \set{x_i : x_i \not \in L(\textsc{LBA}_i)} \) jest taki, że \( L \in \r \setminus \csl{\Sigma}\).
\end{theorem}
\begin{proof}
    Istnieje sposób (skończonego) kodowania Maszyn Turinga, a LBA jest Maszyną Turinga z ograniczoną taśmą. Tym samym Maszyny Turinga (w szczególności LBA) można enumerować, ponieważ jest ich przeliczalnie wiele i tym samym definicja języka \( L \) jest poprawna.
        
    \begin{lemma}
        \( L \not \in \csl{\Sigma}\)
    \end{lemma}
    \begin{proof}
        Założmy, że język \(L\) jest kontekstowy. W takim razie istnieje LBA, które go rozpoznaje, a zatem musi być \(k\)-te w kolejności ze wszystkich LBA w jakimś porządku (ozn. \( \textsc{LBA}_k \) dla \(k \in \natural \) ). Rozważmy \(k\)-te słowo w naszym porządku na słowach:
        \[ w_k \in L(\textsc{LBA}_k) \iff w_k \in L \]
        Jako że \( L = L(\textsc{LBA}_k) \) z założenia nie wprost. 
        
        Jednocześnie z defnicji \(L\):
        \[ w_k \in L  \iff w_k \not \in  L(\textsc{LBA}_k), \]
        skąd:
        \[ w_k \not \in  L(\textsc{LBA}_k) \iff w_k \in L \iff w_k \in L(\textsc{LBA}_k), \]
        co prowadzi do sprzeczności.
    \end{proof}
\end{proof}

    \begin{lemma}
        \( L \in \r \)
    \end{lemma}
    \begin{proof}
        Problem stopu dla LBA jest rozstrzygalny, bo LBA może mieć jedynie skończenie wiele konfiguracji (istnieje więc MT spamiętująca, która konfiguracja wystąpiła, a która nie). W takim razie istnieje Maszyna Turinga, która dla zadanego słowa może policzyć jego numer w alfabecie, a następnie wygenerować \(k\)-te LBA i sprawdzić, czy zawiesi się na tym słowie i jaki będzie wynik jego działania. Tym samym język ten jest rekurencyjny. 
    \end{proof}

\subsubsection{Przykład języka rekurencyjnie przeliczalnego}

\begin{theorem}
    Język stopu (\(L_{HP}\)) jest rekurencyjnie przeliczalny i nie jest rekurencyjny. 
\end{theorem}
\begin{proof}
    Patrz: sekcja \ref{lhp}.
\end{proof}